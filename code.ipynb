{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.25 MiB for an array with shape (3, 3, 256, 256) and data type float32. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50\n",
    "\n",
    "# Prepare the data\n",
    "train_path = \"data/Train_Validation sets\"\n",
    "test_path = \"data/Independent Test Set\"\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(train_path, target_size=(64, 64), color_mode='rgb', class_mode='sparse', batch_size=64)\n",
    "test_generator = datagen.flow_from_directory(test_path, target_size=(64, 64), color_mode='rgb', class_mode='sparse', batch_size=64, shuffle=False)\n",
    "\n",
    "# Define custom CNN model\n",
    "def create_custom_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3,3), input_shape=(64, 64, 3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        Conv2D(64, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv2D(128, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        Conv2D(128, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Conv2D(256, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        Conv2D(256, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        Conv2D(256, (3,3), padding=\"same\"),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define VGG16 model with fine-tuning\n",
    "def create_vgg16_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    for layer in base_model.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define VGG19 model with fine-tuning\n",
    "def create_vgg19_model():\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    for layer in base_model.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define ResNet50 model with fine-tuning\n",
    "def create_resnet50_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    for layer in base_model.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train and evaluate models\n",
    "models = [create_custom_model(), create_vgg16_model(), create_vgg19_model(), create_resnet50_model()]\n",
    "model_names = ['Custom Model', 'VGG16', 'VGG19', 'ResNet50']\n",
    "accuracies = []\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    print(f\"Training {name}...\")\n",
    "    history = model.fit(train_generator, validation_data=test_generator, epochs=30, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"{name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracies, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
